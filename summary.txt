/#################/
PyCon 2018 Summary
Leo Robinovitch
/#################/

__________________________________________________
___ All notes from talks, tutorials, sprints:  ___

*** https://github.com/robinovitch61/pycon2018 ***
__________________________________________________


...........................

__________________________________________________________________
_____________________ Videos from PyCon2018  _____________________

*** https://www.youtube.com/channel/UCsX05-2sVSH7Nx3zuk3NYuQ ***
__________________________________________________________________


...........................


----------------------------------------------------------------------
Tools worth checking out, in general order of most --> least exciting:
----------------------------------------------------------------------

** dask **: a really exciting replacement for pyspark
  * Demo: https://www.youtube.com/watch?v=N_GqzcuGLCY
  * PyCon2018 Talk: https://www.youtube.com/watch?v=Iq72dt1gO9c
  - Features:
    - Pandas syntax (dask dataframes)
    - Built on numpy, written in python, C, and Fortran
    - No Java required (unlike pyspark)
    - Less errors as well as comprehensible errors and stacktraces (no vague memory errors, "Container Killed by YARN"...)
    - Benchmarked at 400% faster locally, 20% faster on cluster for same jobs relative to pyspark
    - Useful diagnostics and visual feedback during runtime -- trace each process and see where time is spent
  - Drawbacks:
    - In rapid development (not yet stable)
    - Limited support for complex parquets (nested hierarchies)
    - Currently recommended for Kubernetes-managed clusters, but hadoop yarn interface tools coming out this month

** pipenv **: the future requirements.txt
  * PyCon2018 Talk: https://www.youtube.com/watch?v=GBQAKldqgZs
  - Features:
    - It's pip, but builds a Pipfile upon each install in the project directory that tracks your environment as you build it up.
    - Upon build of virtual environment, creates lock file that contains all the details (sub-dependancies, git hashes, etc.)
    - Will eventually be incorporated into pip and replace virtualenv and provide alternative to conda envs (currently functional but called pipenv and not yet pip)
    

** Continuous integration tools: Travis-CI, Appveyor (Travis for Windows), Jenkins **: automates tests upon push to version control (or on commit locally)
  - Do we have this already at Tesla? I am excited to use CI tools for my projects.


** Gitannex and Datalab **: methods of versioning files too large to actually check-in to version control
git-annex:
  - built on git, manage files with git without actually checking the files in
  - add special remotes, other fancy features
Datalad:
  - relies on git and git-annex, organizes repos into super-datasets
  - aggs metadata (searchable)
  - python api -- import symbolic links to data from github

** AsyncIO + Multiprocessing **: package made by facebook for high-performance python
  * Package Repo: https://github.com/jreese/aiomultiprocess
  * PyCon2018 Talk: https://www.youtube.com/watch?v=0kXaLh8Fz3k
  - Seems advanced and use-case specific, but sample code performance increased by 500% with this package

** PYMC3 **: Bayesian models made easy in Python
  * PyCon2018 Talk: https://www.youtube.com/watch?v=-sIOMs4MSuA
  * Repo + Examples: https://github.com/pymc-devs/pymc3/tree/master/docs/source/notebooks
  * Blog Post on Gaussian Parameter Fitting: https://sidravi1.github.io/blog/2018/05/15/latent-gp-and-binomial-likelihood
  * Bayesian Stats for Hackers uses PYMC3: https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers
  
  
  
----------------------------------------------------------------------
Tutorials and Resources Worth Checking Out:
----------------------------------------------------------------------

* Docker and docker-compose tutorial repo: https://github.com/docker-for-data-science/docker-for-data-science-tutorial

* Free Digital Books by Allen Downey -- Frequentis+Bayesian Stats, Digital Signal Processing, Complexity Science, etc., with python examples: http://greenteapress.com/wp/

* Python library for digital signal processing: https://github.com/AllenDowney/ThinkDSP

* Digital signal processing slides: https://docs.google.com/presentation/d/e/2PACX-1vSBDcuVO5-zRovw9wlegdSdEEuNG_fYxBtdKyMiqTskdTKJrbl6qcqj04gwWiVdHGlgVv1LBLd-uLW_/pub?slide=id.g1b100a4094_0_1

* Complexity Science slides: https://docs.google.com/presentation/d/e/2PACX-1vRZe91r-yMDmvTm1r4bnNdaC1Ib8jHN4Y7c-_C86TmhyudEvmm4cyioUcT15nJtxDd_XCSli5qhiD1S/pub?slide=id.p

* Docker slides: https://docs.google.com/presentation/d/11y8C-5u35_7--IUPuI4i4Xqiy-FUcR1GAERdJg692c8/edit#slide=id.g2ac1e6ff1d_0_0


----------------------------------------------------------------------
Stand-Alone Talks Worth Checking Out:
----------------------------------------------------------------------

* Writing Code for Pre-Existing Code Bases:
  * https://www.youtube.com/watch?v=LDdUuoI_lIg
  
* Seven Ways to Optimize Numerical Python: https://www.youtube.com/watch?v=c5DV9Nur1W8

* Debugging PySpark: https://www.youtube.com/watch?v=McgG09XriEI
  - Note: spark 2.2+ has more useful error info passed to jupyter notebooks








* Kubernetes: "a system you run on a cluster that allows many distributed systems to run on that cluster"
  * Can manage jupyterhub and dask, see Matthew Rocklin's Dask talk

* Glom: nested data operator for python

* Tools for monitoring: prometheus for time series, grafana, nagios

* numba

* cookiecutter


* virtual environments, version control and git collaboration: https://github.com/chalmerlowe/intro_to_sprinting/tree/master/class_materials

* git branching model for development: http://nvie.com/posts/a-successful-git-branching-model/

* open-sourcing things

* Surprise library for singular value decomposition, recommender algorithms

* XND: not too useful right now, but future implementation of numpy (supports more types, ragged arrays, more modular)

* recipy, nbval



* Type annotations: https://www.python.org/dev/peps/pep-0484/
  * mypy
  
* Animations in python: p5

* AREPL, tool for real-time code evaluation: https://github.com/Almenon/AREPL

* xarray -- pandas in multiple dimensions

* reproducible workflows: http://bitsandchips.me/Talks/PyCon.html
  * the "Bus Factor" -- how many people getting hit by busses would it take for this project to be stopped?
  

