{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting from Spark to Dask: What to Expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literally showed the spark error I get all the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask Promised:\n",
    "* No more java head space\n",
    "* No container killed by Yarn\n",
    "* No bs that spark has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is Really: kind of like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark: general data processing engine\n",
    "* batch, stream processing, sql engine\n",
    "* Hadoop yarn, ec2, mesos, local cluster\n",
    "* Many languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask: parallel computing library for analytic computing\n",
    "* Built on numpy, written in python, C and fortran\n",
    "* Hadoop yarn, ec2, mesos, local cluster, kubernetes\n",
    "* Python only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow: read parquet, agg, transform, json write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data partitioned by some columns, contains one or more parquet files in each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd = dask_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby for timestamps -- round to closest minute, hour, etc!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has exact same syntax as pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agg output has multiindex -- manually set columns to flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is fast -- 3-4x faster than spark on local machine, a little bit faster (1.2ish) on cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is recommended to be deployed with Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask in reality:\n",
    "* No java heap space\n",
    "* No container killed by ARN\n",
    "* Meaningful stack traces\n",
    "* Visual feedback -- see what's taking the most time\n",
    "* All python familiar if coming from pandas\n",
    "* pip install dask, ready to run\n",
    "* Bad:\n",
    "  * Limited support for complex parquets (objects in objects, not good for hierarchies)\n",
    "  * Required workaround for writing to json\n",
    "  * Doesn't support as many agg functions\n",
    "  * More bugs, less docs\n",
    "  * Cluster deployments are WIP\n",
    "  * In flux\n",
    "  * Doesn't support sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask developers:\n",
    "* Martin Durant\n",
    "* Matthew Rocklin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
