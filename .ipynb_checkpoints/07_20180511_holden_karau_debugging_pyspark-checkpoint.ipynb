{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code review livestreams, check em out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark works with Kubernetes, but not with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging distributed systems and mixed language and lazy evaluation systems is hard -- pyspark is all these things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark: general purpose distributed system, apache project, much faster than hadoop map/reduce, rdd and dataset abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons for spark: job is too long or dataframe won't fit in local memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of lazy execution, can't debug anything until the final execution statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined JVM and python stacktrace, sucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of memory exception, classsic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protip: think about where things might be broken, then go in the logs and check yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up spark history server -- allows looking at logs after things have crashed\n",
    "* Check out yarn.nodemanager.dlete.debug-delay-sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change log level with sc.setLogLevel -- can dynamically change this in different parts of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JVM Stacktrace:\n",
    "* Python stacktrace wrapped in java wrapped in java wrapped in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPGRADE TO SPARK 2.2+, PASS USEFUL INFORMATION INTO JUPYTER ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all tasks failed -- not based on data, probably based on code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, ignore java stacktraces and look for python stacktrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scala, can look at directed acyclic graph -- the boxes and arrows\n",
    "* Not the case in python\n",
    "* In pyspark, DAG visualization is generated inside of Scala, so misses python pielines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take() and count() help -- persist also helps to avoid the lazy evaluation difficulties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambdas aren't always good -- e.g. lambda x,y:x/y when y=0, stacktrace won't help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write tests for things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install spark-testing-base (see talk on youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
